{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "colonial-colon",
   "metadata": {},
   "source": [
    "# This notebook is a WIP for forced alignment using Wav2Vec2. Most code comes from the DSAlign project which uses DeepSpeech for transcribing files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288e9ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import logging\n",
    "import subprocess\n",
    "import os.path as path\n",
    "import numpy as np\n",
    "import textdistance\n",
    "from collections import Counter\n",
    "from search import FuzzySearch\n",
    "from glob import glob\n",
    "from text import Alphabet, TextCleaner, levenshtein, similarity\n",
    "from utils import enweight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07fc13a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "BEAM_WIDTH = 500\n",
    "LM_ALPHA = 1\n",
    "LM_BETA = 1.85\n",
    "\n",
    "ALGORITHMS = ['WNG', 'jaro_winkler', 'editex', 'levenshtein', 'mra', 'hamming']\n",
    "SIM_DESC = 'From 0.0 (not equal at all) to 100.0 (totally equal)'\n",
    "NAMED_NUMBERS = {\n",
    "    'tlen': ('transcript length', int, None),\n",
    "    'mlen': ('match length', int, None),\n",
    "    'SWS': ('Smith-Waterman score', float, 'From 0.0 (not equal at all) to 100.0+ (pretty equal)'),\n",
    "    'WNG': ('weighted N-gram similarity', float, SIM_DESC),\n",
    "    'jaro_winkler': ('Jaro-Winkler similarity', float, SIM_DESC),\n",
    "    'editex': ('Editex similarity', float, SIM_DESC),\n",
    "    'levenshtein': ('Levenshtein similarity', float, SIM_DESC),\n",
    "    'mra': ('MRA similarity', float, SIM_DESC),\n",
    "    'hamming': ('Hamming similarity', float, SIM_DESC),\n",
    "    'CER': ('character error rate', float, 'From 0.0 (no different words) to 100.0+ (total miss)'),\n",
    "    'WER': ('word error rate', float, 'From 0.0 (no wrong characters) to 100.0+ (total miss)')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b7d6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_script(script_path):\n",
    "    tc = TextCleaner(alphabet,\n",
    "                     dashes_to_ws=True,\n",
    "                     normalize_space=True,\n",
    "                     to_lower=True)\n",
    "    with open(script_path, 'r', encoding='utf-8') as script_file:\n",
    "        content = script_file.read()\n",
    "        tc.add_original_text(content)\n",
    "    return tc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17482dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "\n",
    "def read_audio(path: str, target_sr: int = 16000):\n",
    "    #assert torchaudio.get_audio_backend() == 'soundfile'\n",
    "    wav, sr = torchaudio.load(path)\n",
    "    if wav.size(0) > 1:\n",
    "        wav = wav.mean(dim=0, keepdim=True)\n",
    "    if sr != target_sr:\n",
    "        transform = torchaudio.transforms.Resample(orig_freq=sr, new_freq=target_sr)\n",
    "        wav = transform(wav)\n",
    "        sr = target_sr\n",
    "\n",
    "    assert sr == target_sr\n",
    "    return wav.squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ff8faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def align(triple):\n",
    "    tlog, script, aligned = triple\n",
    "\n",
    "    logging.debug(\"Loading script from %s...\" % script)\n",
    "    tc = read_script(script)\n",
    "    search = FuzzySearch(tc.clean_text,\n",
    "                         max_candidates=10,\n",
    "                         candidate_threshold=0.92,\n",
    "                         match_score=100,\n",
    "                         mismatch_score=-100,\n",
    "                         gap_score=-100)\n",
    "\n",
    "    logging.debug(\"Loading transcription log from %s...\" % tlog)\n",
    "    with open(tlog, 'r', encoding='utf-8') as transcription_log_file:\n",
    "        fragments = json.load(transcription_log_file)\n",
    "    end_fragments = len(fragments)\n",
    "    fragments = fragments[0:end_fragments]\n",
    "    for index, fragment in enumerate(fragments):\n",
    "        meta = {}\n",
    "        for key, value in list(fragment.items()):\n",
    "            if key not in ['start', 'end', 'transcript']:\n",
    "                meta[key] = value\n",
    "                del fragment[key]\n",
    "        fragment['meta'] = meta\n",
    "        fragment['index'] = index\n",
    "        fragment['transcript'] = fragment['transcript'].strip()\n",
    "\n",
    "    reasons = Counter()\n",
    "\n",
    "    def skip(index, reason):\n",
    "        logging.info('Fragment {}: {}'.format(index, reason))\n",
    "        reasons[reason] += 1\n",
    "\n",
    "    def split_match(fragments, start=0, end=-1):\n",
    "        n = len(fragments)\n",
    "        if n < 1:\n",
    "            return\n",
    "        elif n == 1:\n",
    "            weighted_fragments = [(0, fragments[0])]\n",
    "        else:\n",
    "            # so we later know the original index of each fragment\n",
    "            weighted_fragments = enumerate(fragments)\n",
    "            # assigns high values to long statements near the center of the list\n",
    "            weighted_fragments = enweight(weighted_fragments)\n",
    "            weighted_fragments = map(lambda fw: (fw[0], (1 - fw[1]) * len(fw[0][1]['transcript'])), weighted_fragments)\n",
    "            # fragments with highest weights first\n",
    "            weighted_fragments = sorted(weighted_fragments, key=lambda fw: fw[1], reverse=True)\n",
    "            # strip weights\n",
    "            weighted_fragments = list(map(lambda fw: fw[0], weighted_fragments))\n",
    "            \n",
    "        for index, fragment in weighted_fragments:\n",
    "            match = search.find_best(fragment['transcript'], start=start, end=end)\n",
    "            match_start, match_end, sws_score, match_substitutions = match\n",
    "            if sws_score > (n - 1) / (2 * n):\n",
    "                fragment['match-start'] = match_start\n",
    "                fragment['match-end'] = match_end\n",
    "                fragment['sws'] = sws_score\n",
    "                fragment['substitutions'] = match_substitutions\n",
    "                for f in split_match(fragments[0:index], start=start, end=match_start):\n",
    "                    yield f\n",
    "                yield fragment\n",
    "                for f in split_match(fragments[index + 1:], start=match_end, end=end):\n",
    "                    yield f\n",
    "                return\n",
    "            \n",
    "        for _, _ in weighted_fragments:\n",
    "            yield None\n",
    "\n",
    "    matched_fragments = split_match(fragments)\n",
    "    matched_fragments = list(filter(lambda f: f is not None, matched_fragments))\n",
    "\n",
    "    similarity_algos = {}\n",
    "\n",
    "    def phrase_similarity(algo, a, b):\n",
    "        if algo in similarity_algos:\n",
    "            return similarity_algos[algo](a, b)\n",
    "        algo_impl = lambda aa, bb: None\n",
    "        if algo.lower() == 'wng':\n",
    "            algo_impl = similarity_algos[algo] = lambda aa, bb: similarity(\n",
    "                aa,\n",
    "                bb,\n",
    "                direction=1,\n",
    "                min_ngram_size=1,\n",
    "                max_ngram_size=3,\n",
    "                size_factor=1,\n",
    "                position_factor=2.5)\n",
    "        elif algo in ALGORITHMS:\n",
    "            algo_impl = similarity_algos[algo] = getattr(textdistance, algo).normalized_similarity\n",
    "        else:\n",
    "            raise Exception('Unknown similarity metric \"{}\"'.format(algo))\n",
    "        return algo_impl(a, b)\n",
    "\n",
    "    def get_similarities(a, b, n, gap_text, gap_meta, direction):\n",
    "        if direction < 0:\n",
    "            a, b, gap_text, gap_meta = a[::-1], b[::-1], gap_text[::-1], gap_meta[::-1]\n",
    "        similarities = list(map(\n",
    "            lambda i: (1.5 if gap_text[i + 1] == ' ' else 1) *\n",
    "                      (1.0 if gap_meta[i + 1] is None else 1) *\n",
    "                      (phrase_similarity('wng', a, b + gap_text[1:i + 1])),\n",
    "            range(n)))\n",
    "        best = max((v, i) for i, v in enumerate(similarities))[1] if n > 0 else 0\n",
    "        return best, similarities\n",
    "\n",
    "    for index in range(len(matched_fragments) + 1):\n",
    "        if index > 0:\n",
    "            a = matched_fragments[index - 1]\n",
    "            a_start, a_end = a['match-start'], a['match-end']\n",
    "            a_len = a_end - a_start\n",
    "            a_stretch = int(a_len * 0.25)\n",
    "            a_shrink = int(a_len * 0.1)\n",
    "            a_end = a_end - a_shrink\n",
    "            a_ext = a_shrink + a_stretch\n",
    "        else:\n",
    "            a = None\n",
    "            a_start = a_end = 0\n",
    "        if index < len(matched_fragments):\n",
    "            b = matched_fragments[index]\n",
    "            b_start, b_end = b['match-start'], b['match-end']\n",
    "            b_len = b_end - b_start\n",
    "            b_stretch = int(b_len * 0.25)\n",
    "            b_shrink = int(b_len * 0.1)\n",
    "            b_start = b_start + b_shrink\n",
    "            b_ext = b_shrink + b_stretch\n",
    "        else:\n",
    "            b = None\n",
    "            b_start = b_end = len(search.text)\n",
    "\n",
    "        assert a_end <= b_start\n",
    "        assert a_start <= a_end\n",
    "        assert b_start <= b_end\n",
    "        if a_end == b_start or a_start == a_end or b_start == b_end:\n",
    "            continue\n",
    "        gap_text = tc.clean_text[a_end - 1:b_start + 1]\n",
    "        gap_meta = tc.meta[a_end - 1:b_start + 1]\n",
    "\n",
    "        if a:\n",
    "            a_best_index, a_similarities = get_similarities(a['transcript'],\n",
    "                                                            tc.clean_text[a_start:a_end],\n",
    "                                                            min(len(gap_text) - 1, a_ext),\n",
    "                                                            gap_text,\n",
    "                                                            gap_meta,\n",
    "                                                            1)\n",
    "            a_best_end = a_best_index + a_end\n",
    "        if b:\n",
    "            b_best_index, b_similarities = get_similarities(b['transcript'],\n",
    "                                                            tc.clean_text[b_start:b_end],\n",
    "                                                            min(len(gap_text) - 1, b_ext),\n",
    "                                                            gap_text,\n",
    "                                                            gap_meta,\n",
    "                                                            -1)\n",
    "            b_best_start = b_start - b_best_index\n",
    "\n",
    "        if a and b and a_best_end > b_best_start:\n",
    "            overlap_start = b_start - len(b_similarities)\n",
    "            a_similarities = a_similarities[overlap_start - a_end:]\n",
    "            b_similarities = b_similarities[:len(a_similarities)]\n",
    "            best_index = max((sum(v), i) for i, v in enumerate(zip(a_similarities, b_similarities)))[1]\n",
    "            a_best_end = b_best_start = overlap_start + best_index\n",
    "\n",
    "        if a:\n",
    "            a['match-end'] = a_best_end\n",
    "        if b:\n",
    "            b['match-start'] = b_best_start\n",
    "\n",
    "    def apply_number(number_key, index, fragment, show, get_value):\n",
    "        kl = number_key.lower()\n",
    "        should_output = True\n",
    "        min_val = None\n",
    "        max_val = None\n",
    "        if kl.endswith('len') and min_val is None:\n",
    "            min_val = 1\n",
    "        if should_output or min_val or max_val:\n",
    "            val = get_value()\n",
    "            if not kl.endswith('len'):\n",
    "                show.insert(0, '{}: {:.2f}'.format(number_key, val))\n",
    "                if should_output:\n",
    "                    fragment[kl] = val\n",
    "            reason_base = '{} ({})'.format(NAMED_NUMBERS[number_key][0], number_key)\n",
    "            reason = None\n",
    "            if min_val and val < min_val:\n",
    "                reason = reason_base + ' too low'\n",
    "            elif max_val and val > max_val:\n",
    "                reason = reason_base + ' too high'\n",
    "            if reason:\n",
    "                skip(index, reason)\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    substitutions = Counter()\n",
    "    result_fragments = []\n",
    "    for fragment in matched_fragments:\n",
    "        index = fragment['index']\n",
    "        time_start = fragment['start']\n",
    "        time_end = fragment['end']\n",
    "        fragment_transcript = fragment['transcript']\n",
    "        result_fragment = {\n",
    "            'start': time_start,\n",
    "            'end': time_end\n",
    "        }\n",
    "        sample_numbers = []\n",
    "\n",
    "        if apply_number('tlen', index, result_fragment, sample_numbers, lambda: len(fragment_transcript)):\n",
    "            continue\n",
    "        result_fragment['transcript'] = fragment_transcript\n",
    "\n",
    "        if 'match-start' not in fragment or 'match-end' not in fragment:\n",
    "            skip(index, 'No match for transcript')\n",
    "            continue\n",
    "        match_start, match_end = fragment['match-start'], fragment['match-end']\n",
    "        if match_end - match_start <= 0:\n",
    "            skip(index, 'Empty match for transcript')\n",
    "            continue\n",
    "        original_start = tc.get_original_offset(match_start)\n",
    "        original_end = tc.get_original_offset(match_end)\n",
    "        result_fragment['text-start'] = original_start\n",
    "        result_fragment['text-end'] = original_end\n",
    "\n",
    "        meta_dict = {}\n",
    "        for meta in list(tc.collect_meta(match_start, match_end)) + [fragment['meta']]:\n",
    "            for key, value in meta.items():\n",
    "                if key == 'text':\n",
    "                    continue\n",
    "                if key in meta_dict:\n",
    "                    values = meta_dict[key]\n",
    "                else:\n",
    "                    values = meta_dict[key] = []\n",
    "                if value not in values:\n",
    "                    values.append(value)\n",
    "        result_fragment['meta'] = meta_dict\n",
    "\n",
    "        result_fragment['aligned-raw'] = tc.original_text[original_start:original_end].strip()\n",
    "\n",
    "        fragment_matched = tc.clean_text[match_start:match_end]\n",
    "        if apply_number('mlen', index, result_fragment, sample_numbers, lambda: len(fragment_matched)):\n",
    "            continue\n",
    "        result_fragment['aligned'] = fragment_matched\n",
    "\n",
    "        if apply_number('SWS', index, result_fragment, sample_numbers, lambda: 100 * fragment['sws']):\n",
    "            continue\n",
    "\n",
    "        should_skip = False\n",
    "        for algo in ALGORITHMS:\n",
    "            should_skip = should_skip or apply_number(algo, index, result_fragment, sample_numbers,\n",
    "                                                      lambda: 100 * phrase_similarity(algo,\n",
    "                                                                                      fragment_matched,\n",
    "                                                                                      fragment_transcript))\n",
    "        if should_skip:\n",
    "            continue\n",
    "\n",
    "        if apply_number('CER', index, result_fragment, sample_numbers,\n",
    "                        lambda: 100 * levenshtein(fragment_transcript, fragment_matched) /\n",
    "                                len(fragment_matched)):\n",
    "            continue\n",
    "\n",
    "        if apply_number('WER', index, result_fragment, sample_numbers,\n",
    "                        lambda: 100 * levenshtein(fragment_transcript.split(), fragment_matched.split()) /\n",
    "                                len(fragment_matched.split())):\n",
    "            continue\n",
    "\n",
    "        substitutions += fragment['substitutions']\n",
    "\n",
    "        result_fragments.append(result_fragment)\n",
    "        logging.debug('Fragment %d aligned with %s' % (index, ' '.join(sample_numbers)))\n",
    "        logging.debug('- T: ' + 10 * ' ' + '\"%s\"' % fragment_transcript)\n",
    "        logging.debug('- O: %s|%s|%s' % (\n",
    "            tc.clean_text[match_start - 10:match_start],\n",
    "            fragment_matched,\n",
    "            tc.clean_text[match_end:match_end + 10]))\n",
    "\n",
    "    with open(aligned, 'w', encoding='utf-8') as result_file:\n",
    "        result_file.write(json.dumps(result_fragments, indent=4, ensure_ascii=False))\n",
    "\n",
    "    return aligned, len(result_fragments), len(fragments) - len(result_fragments), reasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ae5a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "sad_model = torch.hub.load(\n",
    "            repo_or_dir='pyannote/pyannote-audio',\n",
    "            model='sad',\n",
    "            pipeline=True,\n",
    "            force_reload=False,\n",
    "            device='cuda')\n",
    "\n",
    "def get_timestamps(path):\n",
    "    sad_results = sad_model({'audio': path})\n",
    "    speech_timestamps = []\n",
    "    for speech_region in sad_results.get_timeline():\n",
    "        speech_timestamps.append({ 'start': int(speech_region.start * 16000), 'end': int(speech_region.end * 16000) })\n",
    "        \n",
    "    return speech_timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40120fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCTC, Wav2Vec2Processor\n",
    "\n",
    "## English ASR, replace with your lang from: https://huggingface.co/models?search=wav2vec2\n",
    "model_name = 'facebook/wav2vec2-large-xlsr-53'\n",
    "\n",
    "model = AutoModelForCTC.from_pretrained(model_name).to(\"cuda\")\n",
    "processor = Wav2Vec2Processor.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbf9c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stt(sample):\n",
    "    audio, time_start, time_end = sample\n",
    "    \n",
    "    input_values = processor(audio, sampling_rate=16_000, return_tensors=\"pt\").input_values.to(\"cuda\")\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_values).logits.cpu().numpy()[0]\n",
    "        \n",
    "    predicted_ids = torch.argmax(model(input_values).logits, -1)\n",
    "    transcript = processor.decode(predicted_ids[0])\n",
    "    return time_start, time_end, ' '.join(transcript.split()).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fec40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug helpers\n",
    "logging.basicConfig()\n",
    "logging.root.setLevel(logging.DEBUG)\n",
    "\n",
    "def resolve(base_path, spec_path):\n",
    "    if spec_path is None:\n",
    "        return None\n",
    "    if not path.isabs(spec_path):\n",
    "        spec_path = path.join(base_path, spec_path)\n",
    "    return spec_path\n",
    "\n",
    "def exists(file_path):\n",
    "    if file_path is None:\n",
    "        return False\n",
    "    return os.path.isfile(file_path)\n",
    "\n",
    "to_prepare = []\n",
    "audio = 'path to audio'\n",
    "script = 'path to script'\n",
    "tlog = 'output.tlog.json'\n",
    "aligned = 'output.aligned.json'\n",
    "alphabet_path = 'alphabet.txt'\n",
    "alphabet = Alphabet(alphabet_path)\n",
    "to_prepare.append((audio, tlog, script, aligned))\n",
    "\n",
    "logging.debug('Start')\n",
    "\n",
    "to_align = []\n",
    "output_graph_path = None\n",
    "for audio_path, tlog_path, script_path, aligned_path in to_prepare:\n",
    "    if not exists(tlog_path):\n",
    "        # Run VAD on the input file\n",
    "        logging.debug('Transcribing VAD segments...')\n",
    "        time_stamps = get_timestamps(audio_path)\n",
    "        raw_audio = read_audio(audio_path)\n",
    "        segments = [(raw_audio[ts['start']:ts['end']], ts['start'], ts['end']) for ts in time_stamps]\n",
    "        del raw_audio\n",
    "\n",
    "        transcripts = [stt(t) for t in segments]\n",
    "\n",
    "        fragments = []\n",
    "        for time_start, time_end, segment_transcript in transcripts:\n",
    "            if segment_transcript:\n",
    "                fragments.append({\n",
    "                    'start': time_start,\n",
    "                    'end': time_end,\n",
    "                    'transcript': segment_transcript\n",
    "                })\n",
    "        logging.debug('Excluded {} empty transcripts'.format(len(transcripts) - len(fragments)))\n",
    "\n",
    "        logging.debug('Writing transcription log to file \"{}\"...'.format(tlog_path))\n",
    "        with open(tlog_path, 'w', encoding='utf-8') as tlog_file:\n",
    "            tlog_file.write(json.dumps(fragments, indent=4, ensure_ascii=False))\n",
    "\n",
    "    if not path.isfile(tlog_path):\n",
    "        raise Exception('Problem loading transcript from \"{}\"'.format(tlog_path))\n",
    "    to_align.append((tlog_path, script_path, aligned_path))\n",
    "\n",
    "total_fragments = 0\n",
    "dropped_fragments = 0\n",
    "reasons = Counter()\n",
    "\n",
    "index = 0\n",
    "for a in to_align:\n",
    "    aligned_file, file_total_fragments, file_dropped_fragments, file_reasons = align(a)\n",
    "    index += 1\n",
    "    logging.info('Aligned file {} of {} - wrote results to \"{}\"'.format(index, len(to_align), aligned_file))\n",
    "    total_fragments += file_total_fragments\n",
    "    dropped_fragments += file_dropped_fragments\n",
    "    reasons += file_reasons\n",
    "\n",
    "logging.info('Aligned {} fragments'.format(total_fragments))\n",
    "if total_fragments > 0 and dropped_fragments > 0:\n",
    "    logging.info('Dropped {} fragments {:0.2f}%:'.format(dropped_fragments,\n",
    "                                                         dropped_fragments * 100.0 / total_fragments))\n",
    "    for key, number in reasons.most_common():\n",
    "        logging.info(' - {}: {}'.format(key, number))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
